"""
ê°„ë‹¨í•œ Voice to Voice í…ŒìŠ¤íŠ¸ (ë¡œì»¬ ì‹¤í–‰)
Google Gemini 2.0 Flash Expë¥¼ ì‚¬ìš©í•œ ì§ì ‘ ìŒì„± ëŒ€í™”
"""
import asyncio
import sounddevice as sd
import numpy as np
from google import genai
import os
from google.genai import types
from dotenv import load_dotenv

# í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € import
from prompt_manager import prompt_manager
from sensors import simulator

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¤ì •
MODEL = "gemini-2.0-flash-exp"
RATE = 24000
CHANNELS = 1
DTYPE = "int16"

# API í‚¤ í™•ì¸
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    print("âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit(1)

print(f"âœ… Gemini API í‚¤ í™•ì¸: ...{GEMINI_API_KEY[-4:]}")

# Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    client = genai.Client(
        api_key=GEMINI_API_KEY, 
        http_options={"api_version": "v1alpha"}
    )
    print("âœ… Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"âŒ Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    exit(1)

def get_greenhouse_context():
    """í˜„ì¬ ì˜¨ì‹¤ ìƒíƒœë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ìƒì„±"""
    current_values = simulator.current_values
    device_status = simulator.device_status
    
    context = f"""
í˜„ì¬ ì˜¨ì‹¤ ì‹œìŠ¤í…œ ìƒíƒœ:
- ì˜¨ë„: {current_values['temperature']:.1f}Â°C
- ìŠµë„: {current_values['humidity']:.1f}%
- í† ì–‘ ìŠµë„: {current_values['soil']:.1f}%
- ì „ë ¥ ì‚¬ìš©ëŸ‰: {current_values['power']:.1f}W

ì¥ì¹˜ ìƒíƒœ:
- ì¡°ëª…: {'ì¼œì§' if device_status['light'] else 'êº¼ì§'}
- íŒ¬: {'ì¼œì§' if device_status['fan'] else 'êº¼ì§'}
- ê¸‰ìˆ˜: {'ì¼œì§' if device_status['water'] else 'êº¼ì§'}
- ì°½ë¬¸: {'ì—´ë¦¼' if device_status['window'] else 'ë‹«í˜'}
"""
    return context

def get_voice_system_prompt():
    """ìŒì„± ëŒ€í™”ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    base_prompt = prompt_manager.get_basic_system_prompt()
    
    voice_prompt = f"""{base_prompt}

ìŒì„± ëŒ€í™” íŠ¹ë³„ ì§€ì¹¨:
1. ì‘ë‹µì€ 2-3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ í•´ì£¼ì„¸ìš”.
2. ë…¸ë…„ì¸µ ë†ì—… ì¢…ì‚¬ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
3. ê¸°ìˆ ì  ìš©ì–´ë³´ë‹¤ëŠ” ì¼ìƒì ì¸ ë§ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
4. ì¥ì¹˜ ì œì–´ ìš”ì²­ ì‹œ ì•¡ì…˜ íƒœê·¸ë„ í•¨ê»˜ ë§í•´ì£¼ì„¸ìš”.
5. ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ í†¤ìœ¼ë¡œ ëŒ€í™”í•´ì£¼ì„¸ìš”.

{get_greenhouse_context()}
"""
    return voice_prompt

def play_audio(data: bytes):
    """ëª¨ë¸ ì‘ë‹µ ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•˜ëŠ” í•¨ìˆ˜."""
    try:
        audio_array = np.frombuffer(data, dtype=np.int16)
        print("ğŸ”Š AI ì‘ë‹µ ì¬ìƒ ì¤‘...")
        sd.play(audio_array, samplerate=RATE)
        sd.wait()
        print("âœ… ì‘ë‹µ ì¬ìƒ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {str(e)}")

async def read_audio_stream():
    """ë§ˆì´í¬ ì…ë ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°"""
    chunk_duration = 0.5
    frames_per_chunk = int(RATE * chunk_duration)
    silence_threshold = 50  # ë¬´ìŒ ì„ê³„ê°’ (ì¡°ì • ê°€ëŠ¥)
    speech_threshold = 100  # ë°œí™” ì‹œì‘ ì„ê³„ê°’ (ì¡°ì • ê°€ëŠ¥)
    silence_duration = 2.0  # ë¬´ìŒ ì§€ì† ì‹œê°„ (2ì´ˆ)
    chunks_for_silence = int(silence_duration / chunk_duration)
    silent_chunks = 0
    speech_started = False

    print("ğŸ¤ ë§ˆì´í¬ì— ë§ì”€í•´ ì£¼ì„¸ìš”...")
    print("   (ë°œí™” ê°ì§€ í›„ 2ì´ˆ ë¬´ìŒì´ë©´ ìë™ ì¢…ë£Œ)")
    
    with sd.RawInputStream(
        samplerate=RATE, channels=CHANNELS, dtype=DTYPE, blocksize=frames_per_chunk
    ) as stream:
        try:
            while True:
                data, overflowed = stream.read(frames_per_chunk)
                if overflowed:
                    print("!", end="", flush=True)
                else:
                    print(".", end="", flush=True)

                # ìŒì„± í¬ê¸° ê³„ì‚° (RMS ê°’ ì‚¬ìš©)
                audio_data = np.frombuffer(bytes(data), dtype=np.int16)
                rms = np.sqrt(np.mean(np.square(audio_data)))

                # ë°œí™” ì‹œì‘ ê°ì§€
                if not speech_started and rms > speech_threshold:
                    print("\nğŸ™ï¸ ë°œí™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê³„ì† ë§ì”€í•´ ì£¼ì„¸ìš”...")
                    speech_started = True
                    silent_chunks = 0

                # ë°œí™”ê°€ ì‹œì‘ëœ í›„ì—ë§Œ ë¬´ìŒ ê°ì§€
                if speech_started:
                    if rms < silence_threshold:
                        silent_chunks += 1
                        if silent_chunks >= chunks_for_silence:
                            print(f"\nâ¹ï¸ {silence_duration}ì´ˆ ë¬´ìŒ ê°ì§€, ë…¹ìŒ ì¢…ë£Œ")
                            break
                    else:
                        silent_chunks = max(0, silent_chunks - 1)

                yield bytes(data)

        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìê°€ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤.")

async def main():
    """ë©”ì¸ í•¨ìˆ˜ - Gemini Live ì„¸ì…˜ ì‹¤í–‰"""
    
    print("\nğŸš€ ìŠ¤ë§ˆíŠ¸ ì˜¨ì‹¤ Voice to Voice ì‹œì‘!")
    print("="*50)
    
    # Gemini ì„¤ì •
    config = {
        "generation_config": {
            "response_modalities": ["AUDIO"],
            "temperature": 0.7,
            "candidate_count": 1,
        },
        "system_instruction": get_voice_system_prompt(),
    }
    
    try:
        async with client.aio.live.connect(model=MODEL, config=config) as session:
            print("âœ… Gemini Live ì„¸ì…˜ ì—°ê²° ì™„ë£Œ")
            
            while True:
                try:
                    print("\n" + "="*50)
                    print("ğŸ™ï¸ ìŒì„± ì…ë ¥ì„ ì‹œì‘í•˜ì„¸ìš”... (Ctrl+Cë¡œ ì „ì²´ ì¢…ë£Œ)")
                    
                    # ì‹¤ì‹œê°„ ë§ˆì´í¬ ì…ë ¥ ìŠ¤íŠ¸ë¦¬ë°
                    last_chunk = None
                    async for chunk in read_audio_stream():
                        if last_chunk is not None:
                            # ì´ì „ ì²­í¬ëŠ” end_of_turn=Falseë¡œ ì „ì†¡
                            input_data = types.LiveClientRealtimeInput(
                                media_chunks=[
                                    {"data": last_chunk, "mime_type": "audio/pcm"}
                                ]
                            )
                            await session.send(input_data, end_of_turn=False)
                        last_chunk = chunk

                    if last_chunk is not None:
                        # ë§ˆì§€ë§‰ ì²­í¬ë¥¼ end_of_turn=Trueë¡œ ì „ì†¡
                        input_data = types.LiveClientRealtimeInput(
                            media_chunks=[{"data": last_chunk, "mime_type": "audio/pcm"}]
                        )
                        await session.send(input_data, end_of_turn=True)

                        print("â³ Gemini AI ì‘ë‹µ ëŒ€ê¸° ì¤‘...")
                        response_chunks = []
                        async for response in session.receive():
                            if response.data is not None:
                                response_chunks.append(response.data)

                        if response_chunks:
                            complete_audio = b"".join(response_chunks)
                            play_audio(complete_audio)
                        else:
                            print("âŒ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                            
                        print("\nğŸ’¬ ê³„ì† ëŒ€í™”í•˜ì‹œë ¤ë©´ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”...")
                        
                except KeyboardInterrupt:
                    print("\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                except Exception as e:
                    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    print("ğŸ”„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”...")
                    
    except Exception as e:
        print(f"âŒ Gemini Live ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        print("\ní•´ê²° ë°©ë²•:")
        print("1. GEMINI_API_KEYê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("2. ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸")
        print("3. Google AI Studioì—ì„œ API í‚¤ ì¬ë°œê¸‰")

def test_audio_devices():
    """ì˜¤ë””ì˜¤ ì¥ì¹˜ í…ŒìŠ¤íŠ¸"""
    print("\nğŸµ ì˜¤ë””ì˜¤ ì¥ì¹˜ í…ŒìŠ¤íŠ¸")
    print("="*30)
    
    try:
        # ì…ë ¥ ì¥ì¹˜ ëª©ë¡
        print("ğŸ¤ ì…ë ¥ ì¥ì¹˜:")
        devices = sd.query_devices()
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:
                print(f"  {i}: {device['name']}")
        
        # ì¶œë ¥ ì¥ì¹˜ ëª©ë¡  
        print("\nğŸ”Š ì¶œë ¥ ì¥ì¹˜:")
        for i, device in enumerate(devices):
            if device['max_output_channels'] > 0:
                print(f"  {i}: {device['name']}")
                
        # ê¸°ë³¸ ì¥ì¹˜ ì •ë³´
        default_device = sd.query_devices(kind='input')
        print(f"\nê¸°ë³¸ ì…ë ¥ ì¥ì¹˜: {default_device['name']}")
        
        default_device = sd.query_devices(kind='output')
        print(f"ê¸°ë³¸ ì¶œë ¥ ì¥ì¹˜: {default_device['name']}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ì¥ì¹˜ í™•ì¸ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    print("ğŸ™ï¸ ìŠ¤ë§ˆíŠ¸ ì˜¨ì‹¤ Voice to Voice í…ŒìŠ¤íŠ¸")
    print("Google Gemini 2.0 Flash Exp ì‚¬ìš©")
    print("="*50)
    
    # ì˜¤ë””ì˜¤ ì¥ì¹˜ í…ŒìŠ¤íŠ¸
    test_audio_devices()
    
    print("\nì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”... (ì¢…ë£Œ: Ctrl+C)")
    try:
        input()
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        import traceback
        print(traceback.format_exc()) 